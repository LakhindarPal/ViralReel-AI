{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lakhindarpal/viralreel-ai-automated-short-form-content?scriptVersionId=292448811\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install -qU google-genai\n!pip install -q git+https://github.com/m-bain/whisperx.git\n!pip install -qU gradio opencv-python gdown yt-dlp \n!pip install -q mediapipe==0.10.14\n\n!wget -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\n\n!apt-get update -y\n!apt-get install -y ffmpeg fonts-roboto","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-17T22:14:09.621389Z","iopub.execute_input":"2026-01-17T22:14:09.621982Z","iopub.status.idle":"2026-01-17T22:14:36.172401Z","shell.execute_reply.started":"2026-01-17T22:14:09.621957Z","shell.execute_reply":"2026-01-17T22:14:36.171498Z"},"trusted":true},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nHit:1 https://cli.github.com/packages stable InRelease\nHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\nHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease     \nHit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease                     \nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nHit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease               \nHit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \nHit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\nHit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\nHit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nfonts-roboto is already the newest version (2:0~20170802-3).\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 128 not upgraded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## IMPORTS\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os, cv2, json, subprocess, re, traceback\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport gradio as gr\nfrom PIL import Image, ImageDraw, ImageFont\nfrom kaggle_secrets import UserSecretsClient\nimport whisperx\nfrom google import genai\nfrom google.genai import types\nimport mediapipe as mp\nfrom mediapipe.tasks import python\nfrom mediapipe.tasks.python import vision","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:36.173965Z","iopub.execute_input":"2026-01-17T22:14:36.17428Z","iopub.status.idle":"2026-01-17T22:14:45.624952Z","shell.execute_reply.started":"2026-01-17T22:14:36.174249Z","shell.execute_reply":"2026-01-17T22:14:45.62438Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2026-01-17 22:14:42.571833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768688082.592973    1911 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768688082.599529    1911 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768688082.616297    1911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768688082.616325    1911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768688082.616327    1911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768688082.616329    1911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## CONFIG\n","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 16\nMAX_DURATION = 60","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:45.625723Z","iopub.execute_input":"2026-01-17T22:14:45.62621Z","iopub.status.idle":"2026-01-17T22:14:45.687544Z","shell.execute_reply.started":"2026-01-17T22:14:45.626186Z","shell.execute_reply":"2026-01-17T22:14:45.686809Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## AUTH\n","metadata":{}},{"cell_type":"code","source":"try:\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    client = genai.Client(api_key=api_key)\nexcept Exception as e:\n    print(f\"‚ùå Secret Error: {e}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:45.689968Z","iopub.execute_input":"2026-01-17T22:14:45.690404Z","iopub.status.idle":"2026-01-17T22:14:45.926023Z","shell.execute_reply.started":"2026-01-17T22:14:45.69038Z","shell.execute_reply":"2026-01-17T22:14:45.925491Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## CORE ENGINE\n","metadata":{}},{"cell_type":"code","source":" class ContentBrain:\n    def __init__(self):\n        print(f\"üöÄ Loading WhisperX on {DEVICE}...\")\n        self.model = whisperx.load_model(\n            \"large-v3-turbo\",\n            DEVICE,\n            compute_type=\"float16\" if DEVICE == \"cuda\" else \"int8\",\n            vad_method=\"silero\",\n        )\n        self.align_model, self.metadata = whisperx.load_align_model(\n            language_code=\"en\", device=DEVICE\n        )\n\n    def transcribe(self, audio_path):\n        result = self.model.transcribe(audio_path, batch_size=BATCH_SIZE)\n        aligned = whisperx.align(\n            result[\"segments\"],\n            self.align_model,\n            self.metadata,\n            audio_path,\n            DEVICE,\n            return_char_alignments=False,\n        )\n        return aligned\n\n    def analyze(self, text):\n        print(\"üß† Thinking (Gemini 2.5 Flash)...\")\n        prompt = f\"\"\"\n        Act as a viral content strategist. Analyze this transcript.\n        Identify exactly 3 segments (30-50s duration) that work as standalone viral shorts.\n        Return JSON ONLY: [{{\"start_text\": \"unique start phrase\", \"end_text\": \"unique end phrase\", \"title\": \"Engaging Headline\"}}]\n        Transcript: {text[:150000]}...\n        \"\"\"\n        try:\n            res = client.models.generate_content(\n                model=\"gemini-2.5-flash\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    temperature=0.7, response_mime_type=\"application/json\"\n                ),\n            )\n            return json.loads(res.text)\n        except:\n            return []","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:45.926881Z","iopub.execute_input":"2026-01-17T22:14:45.927164Z","iopub.status.idle":"2026-01-17T22:14:45.934128Z","shell.execute_reply.started":"2026-01-17T22:14:45.927128Z","shell.execute_reply":"2026-01-17T22:14:45.933376Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class SmartCam:\n    def __init__(self):\n        base_opts = python.BaseOptions(model_asset_path=\"detector.tflite\")\n        opts = vision.FaceDetectorOptions(\n            base_options=base_opts, min_detection_confidence=0.5\n        )\n        self.detector = vision.FaceDetector.create_from_options(opts)\n\n    def get_face_center(self, frame):\n        mp_img = mp.Image(\n            image_format=mp.ImageFormat.SRGB,\n            data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),\n        )\n        res = self.detector.detect(mp_img)\n        if res.detections:\n            largest = max(res.detections, key=lambda d: d.bounding_box.width)\n            return (\n                largest.bounding_box.origin_x + (largest.bounding_box.width / 2)\n            ) / frame.shape[1]\n        return 0.5","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:45.935062Z","iopub.execute_input":"2026-01-17T22:14:45.935556Z","iopub.status.idle":"2026-01-17T22:14:45.950116Z","shell.execute_reply.started":"2026-01-17T22:14:45.935534Z","shell.execute_reply":"2026-01-17T22:14:45.949386Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Renderer:\n    def __init__(self):\n        self.font_path = \"/usr/share/fonts/truetype/roboto/Roboto-Black.ttf\"\n        try:\n            self.font_size = 75\n            self.font = ImageFont.truetype(self.font_path, self.font_size)\n            self.small_font = ImageFont.truetype(self.font_path, 40)\n        except:\n            self.font = ImageFont.load_default()\n            self.small_font = ImageFont.load_default()\n\n    def get_text_width(self, words, draw):\n        total = 0\n        for wd in words:\n            bbox = draw.textbbox((0, 0), wd[\"word\"], font=self.font)\n            total += (bbox[2] - bbox[0]) + 20\n        return total - 20\n\n    def draw_wrapped_title(self, draw, title, w):\n        words = title.upper().split()\n        lines = []\n        curr = []\n        for word in words:\n            test = curr + [word]\n            bbox = draw.textbbox((0, 0), \" \".join(test), font=self.small_font)\n            if (bbox[2] - bbox[0]) < (w - 100):\n                curr = test\n            else:\n                lines.append(\" \".join(curr))\n                curr = [word]\n        lines.append(\" \".join(curr))\n\n        y = 80\n        for line in lines:\n            bbox = draw.textbbox((0, 0), line, font=self.small_font)\n            x = (w - (bbox[2] - bbox[0])) // 2\n            draw.text(\n                (x, y),\n                line,\n                font=self.small_font,\n                fill=\"#00ffff\",\n                stroke_width=3,\n                stroke_fill=\"black\",\n            )\n            y += 50\n\n    def draw_karaoke(self, frame, words, time, title):\n        draw = ImageDraw.Draw(frame)\n        w, h = frame.size\n        self.draw_wrapped_title(draw, title, w)\n\n        active_idx = -1\n        for i, word in enumerate(words):\n            if word[\"start\"] <= time <= word[\"end\"] + 0.2:\n                active_idx = i\n                break\n\n        if active_idx == -1:\n            return frame\n\n        chunk_size = 3\n        start = (active_idx // chunk_size) * chunk_size\n        end = min(len(words), start + chunk_size)\n        visible = words[start:end]\n\n        if self.get_text_width(visible, draw) > (w - 80):\n            visible = [words[active_idx]]\n\n        y = h - 450\n        x = (w - self.get_text_width(visible, draw)) // 2\n\n        for wd in visible:\n            color = \"#FFE135\" if wd == words[active_idx] else \"white\"\n            draw.text(\n                (x, y),\n                wd[\"word\"],\n                font=self.font,\n                fill=color,\n                stroke_width=5,\n                stroke_fill=\"black\",\n            )\n            bbox = draw.textbbox((0, 0), wd[\"word\"], font=self.font)\n            x += (bbox[2] - bbox[0]) + 20\n\n        return frame","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:45.95103Z","iopub.execute_input":"2026-01-17T22:14:45.951526Z","iopub.status.idle":"2026-01-17T22:14:45.97027Z","shell.execute_reply.started":"2026-01-17T22:14:45.951504Z","shell.execute_reply":"2026-01-17T22:14:45.969748Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## WORKER FUNCTIONS\n","metadata":{}},{"cell_type":"code","source":"brain = ContentBrain()\ncam = SmartCam()\nrenderer = Renderer()","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:45.971031Z","iopub.execute_input":"2026-01-17T22:14:45.971205Z","iopub.status.idle":"2026-01-17T22:14:55.617992Z","shell.execute_reply.started":"2026-01-17T22:14:45.971188Z","shell.execute_reply":"2026-01-17T22:14:55.617144Z"},"trusted":true},"outputs":[{"name":"stdout","text":"üöÄ Loading WhisperX on cuda...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n  torchaudio.list_audio_backends()\n/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n  available_backends = torchaudio.list_audio_backends()\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n","output_type":"stream"},{"name":"stdout","text":"2026-01-17 22:14:54 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n2026-01-17 22:14:54 - whisperx.vads.silero - INFO - Performing voice activity detection using Silero...\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1768688095.609700    1911 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nW0000 00:00:1768688095.613740    2754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def clean_filename(title):\n    clean = re.sub(r\"[^\\w\\s-]\", \"\", title).strip().lower()\n    return re.sub(r\"[-\\s]+\", \"_\", clean)","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:55.6189Z","iopub.execute_input":"2026-01-17T22:14:55.619624Z","iopub.status.idle":"2026-01-17T22:14:55.623703Z","shell.execute_reply.started":"2026-01-17T22:14:55.619593Z","shell.execute_reply":"2026-01-17T22:14:55.622956Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def render_worker(args):\n    i, hook, vid_path, all_words = args\n    print(f\"   ‚ñ∂Ô∏è Processing: {hook['title']}\")\n\n    start_t, end_t = 0, 0\n    s_txt, e_txt = hook[\"start_text\"].strip(), hook[\"end_text\"].strip()\n\n    for w in all_words:\n        if s_txt.startswith(w[\"word\"].strip()):\n            start_t = w[\"start\"]\n            break\n\n    if start_t > 0:\n        for w in all_words:\n            if (\n                w[\"start\"] > start_t\n                and w[\"end\"] < (start_t + MAX_DURATION)\n                and e_txt.endswith(w[\"word\"].strip())\n            ):\n                end_t = w[\"end\"]\n\n    if end_t <= start_t:\n        start_t = i * 60 + 60\n        end_t = start_t + 50\n    if (end_t - start_t) > MAX_DURATION:\n        end_t = start_t + MAX_DURATION\n\n    cap = cv2.VideoCapture(vid_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    start_f, end_f = int(start_t * fps), int(end_t * fps)\n\n    safe_title = clean_filename(hook[\"title\"])\n    out = f\"{safe_title}.mp4\"\n    tmp = f\"temp_{i}.mp4\"\n\n    writer = cv2.VideoWriter(tmp, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (720, 1280))\n    cap.set(cv2.CAP_PROP_POS_FRAMES, start_f)\n\n    curr_f = start_f\n    curr_center = 0.5\n\n    while curr_f < end_f:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        tgt_center = cam.get_face_center(frame)\n        curr_center = curr_center * 0.9 + tgt_center * 0.1\n\n        h, w, _ = frame.shape\n        tgt_w = int(h * (9 / 16))\n        if tgt_w % 2 != 0:\n            tgt_w -= 1\n\n        cx = int(curr_center * w)\n        x1 = max(0, min(cx - (tgt_w // 2), w - tgt_w))\n\n        final = cv2.resize(frame[0:h, x1 : x1 + tgt_w], (720, 1280))\n        img = Image.fromarray(cv2.cvtColor(final, cv2.COLOR_BGR2RGB))\n        img = renderer.draw_karaoke(img, all_words, curr_f / fps, hook[\"title\"])\n        writer.write(cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n        curr_f += 1\n\n    cap.release()\n    writer.release()\n\n    subprocess.run(\n        [\n            \"ffmpeg\",\n            \"-y\",\n            \"-i\",\n            tmp,\n            \"-ss\",\n            str(start_t),\n            \"-to\",\n            str(end_t),\n            \"-i\",\n            vid_path,\n            \"-c:v\",\n            \"libx264\",\n            \"-pix_fmt\",\n            \"yuv420p\",\n            \"-preset\",\n            \"ultrafast\",\n            \"-c:a\",\n            \"aac\",\n            \"-map\",\n            \"0:v:0\",\n            \"-map\",\n            \"1:a:0\",\n            \"-shortest\",\n            out,\n        ],\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL,\n    )\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:55.625924Z","iopub.execute_input":"2026-01-17T22:14:55.62627Z","iopub.status.idle":"2026-01-17T22:14:55.64505Z","shell.execute_reply.started":"2026-01-17T22:14:55.626235Z","shell.execute_reply":"2026-01-17T22:14:55.644508Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def run_pipeline(vid_file, url, progress=gr.Progress()):\n    try:\n        # 1. Input\n        path = \"input.mp4\"\n        if vid_file:\n            path = vid_file\n        elif url:\n            progress(0.1, desc=\"Loading Video...\")\n            cmd = [\n                \"yt-dlp\",\n                \"--add-header\",\n                \"User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\",\n                \"-f\",\n                \"bestvideo[ext=mp4][vcodec^=avc]+bestaudio[ext=m4a]/best[ext=mp4]/best\",\n                \"--force-overwrites\",\n                \"-o\",\n                path,\n                url,\n            ]\n            result = subprocess.run(cmd, capture_output=True, text=True)\n            if result.returncode != 0:\n                return [\n                    gr.update(value=None),\n                    gr.update(value=None),\n                    gr.update(value=None),\n                    f\"‚ùå Download Failed:\\n{result.stderr[-200:]}\",\n                ]\n        else:\n            return [\n                gr.update(value=None),\n                gr.update(value=None),\n                gr.update(value=None),\n                \"‚ùå No input provided\",\n            ]\n\n        if not os.path.exists(path):\n            return [\n                gr.update(value=None),\n                gr.update(value=None),\n                gr.update(value=None),\n                \"‚ùå Download failed (File not found)\",\n            ]\n\n        # 2. Audio\n        progress(0.2, desc=\"Analysing Audio...\")\n        subprocess.run(\n            [\n                \"ffmpeg\",\n                \"-y\",\n                \"-i\",\n                path,\n                \"-vn\",\n                \"-acodec\",\n                \"pcm_s16le\",\n                \"-ar\",\n                \"16000\",\n                \"-ac\",\n                \"1\",\n                \"temp.wav\",\n            ],\n            stdout=subprocess.DEVNULL,\n        )\n\n        try:\n            aligned = brain.transcribe(\"temp.wav\")\n        except Exception as e:\n            return [\n                gr.update(value=None),\n                gr.update(value=None),\n                gr.update(value=None),\n                f\"‚ùå Whisper Error: {e}\",\n            ]\n\n        text = \" \".join([s[\"text\"] for s in aligned[\"segments\"]])\n        words = []\n        for s in aligned[\"segments\"]:\n            words.extend(s[\"words\"])\n\n        # 3. AI\n        progress(0.4, desc=\"Selecting Hooks...\")\n        hooks = brain.analyze(text)\n        if not hooks:\n            return [\n                gr.update(value=None),\n                gr.update(value=None),\n                gr.update(value=None),\n                \"‚ùå No viral hooks found by AI\",\n            ]\n\n        # 4. Render\n        progress(0.6, desc=\"Rendering...\")\n        with ThreadPoolExecutor(max_workers=3) as exe:\n            files = list(\n                exe.map(\n                    render_worker, [(i, h, path, words) for i, h in enumerate(hooks)]\n                )\n            )\n\n        # 5. Dynamic Return (Update Labels)\n        outputs = []\n        for i, f in enumerate(files):\n            outputs.append(gr.update(value=f, label=hooks[i][\"title\"]))\n\n        while len(outputs) < 3:\n            outputs.append(gr.update(value=None, label=\"No Reel Generated\"))\n\n        outputs.append(\"‚úÖ Processing Complete!\")\n        return outputs[0], outputs[1], outputs[2], outputs[3]\n\n    except Exception as e:\n        return [\n            gr.update(value=None),\n            gr.update(value=None),\n            gr.update(value=None),\n            f\"‚ùå Critical Error:\\n{str(e)}\",\n        ]","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:55.645812Z","iopub.execute_input":"2026-01-17T22:14:55.646005Z","iopub.status.idle":"2026-01-17T22:14:55.66833Z","shell.execute_reply.started":"2026-01-17T22:14:55.645983Z","shell.execute_reply":"2026-01-17T22:14:55.66771Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## GRADIO UI\n","metadata":{}},{"cell_type":"code","source":"with gr.Blocks(title=\"ViralReel AI\") as app:\n    gr.Markdown(\"# üöÄ ViralReel AI\")\n    gr.Markdown(\"Automated Short-Form Content Generator ¬∑ Powered by Gemini & WhisperX\")\n\n    with gr.Column():\n        with gr.Tabs():\n            with gr.TabItem(\"Upload Video\"):\n                v_in = gr.Video(label=\"Source File\")\n            with gr.TabItem(\"Paste URL\"):\n                l_in = gr.Textbox(\n                    label=\"YouTube / Drive Link\", placeholder=\"https://...\"\n                )\n\n        btn = gr.Button(\"Generate Reels\", variant=\"primary\")\n        status = gr.Textbox(label=\"System Logs\", interactive=False)\n\n    with gr.Row():\n        o1 = gr.Video(label=\"Pending Reel 1...\")\n        o2 = gr.Video(label=\"Pending Reel 2...\")\n        o3 = gr.Video(label=\"Pending Reel 3...\")\n\n    btn.click(run_pipeline, inputs=[v_in, l_in], outputs=[o1, o2, o3, status])\n\napp.queue().launch(share=True, debug=True)","metadata":{"execution":{"iopub.status.busy":"2026-01-17T22:14:55.669125Z","iopub.execute_input":"2026-01-17T22:14:55.669343Z","execution_failed":"2026-01-17T22:37:01.418Z"},"trusted":true},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://60395b6299a5e6a2eb.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://60395b6299a5e6a2eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stderr","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input.mp4':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2avc1mp41\n    encoder         : Lavf58.76.100\n  Duration: 00:25:08.49, start: 0.000000, bitrate: 816 kb/s\n  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 681 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      vendor_id       : [0][0][0][0]\n  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      vendor_id       : [0][0][0][0]\nStream mapping:\n  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'temp.wav':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2avc1mp41\n    ISFT            : Lavf58.76.100\n  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      vendor_id       : [0][0][0][0]\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=   47140kB time=00:25:08.48 bitrate= 256.0kbits/s speed= 696x    \nvideo:0kB audio:47140kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000162%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-17 22:16:27 - whisperx.asr - INFO - Detected language: en (1.00) in first 30s of audio\nüß† Thinking (Gemini 2.5 Flash)...\n   ‚ñ∂Ô∏è Processing: Linus Torvalds: My Wife's Fun vs. Mine (and Skiing Fail)\n   ‚ñ∂Ô∏è Processing: The Staggering Pace of Linux Development: 10,000 Lines a Day!\n   ‚ñ∂Ô∏è Processing: Linus Torvalds: 'Innovation is Bullshit. Get the Work Done.'\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n","output_type":"stream"}],"execution_count":null}]}