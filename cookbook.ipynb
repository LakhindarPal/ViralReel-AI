{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qU google-genai\n!pip install -q git+https://github.com/m-bain/whisperx.git\n!pip install -qU gradio opencv-python gdown yt-dlp \n!pip install -qU mediapipe==0.10.14\n\n!wget -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\n\n!apt-get update -y\n!apt-get install -y ffmpeg fonts-roboto","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-17T20:01:48.918212Z","iopub.execute_input":"2026-01-17T20:01:48.918546Z","iopub.status.idle":"2026-01-17T20:03:02.798228Z","shell.execute_reply.started":"2026-01-17T20:01:48.918519Z","shell.execute_reply":"2026-01-17T20:03:02.797165Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m719.1/719.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.8/897.8 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for whisperx (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\na2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://cli.github.com/packages stable InRelease [3,917 B]               \nGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \nGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nHit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:7 https://cli.github.com/packages stable/main amd64 Packages [354 B]       \nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,619 kB] \nGet:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,302 kB]\nGet:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nHit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \nGet:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \nGet:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\nGet:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,869 kB]\nGet:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [45.0 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,968 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,600 kB]\nGet:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,637 kB]\nFetched 25.8 MB in 4s (6,152 kB/s)   \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\nThe following NEW packages will be installed:\n  fonts-roboto fonts-roboto-unhinted\n0 upgraded, 2 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 2,380 kB of archives.\nAfter this operation, 6,405 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-roboto-unhinted all 2:0~20170802-3 [2,376 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-roboto all 2:0~20170802-3 [3,212 B]\nFetched 2,380 kB in 1s (1,909 kB/s)      \nSelecting previously unselected package fonts-roboto-unhinted.\n(Reading database ... 129073 files and directories currently installed.)\nPreparing to unpack .../fonts-roboto-unhinted_2%3a0~20170802-3_all.deb ...\nUnpacking fonts-roboto-unhinted (2:0~20170802-3) ...\nSelecting previously unselected package fonts-roboto.\nPreparing to unpack .../fonts-roboto_2%3a0~20170802-3_all.deb ...\nUnpacking fonts-roboto (2:0~20170802-3) ...\nSetting up fonts-roboto-unhinted (2:0~20170802-3) ...\nSetting up fonts-roboto (2:0~20170802-3) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- CELL: VIRALREEL AI (DYNAMIC TITLES EDITION) ---\nimport torch\nimport numpy as np\nimport os, cv2, json, subprocess, re, traceback\nfrom concurrent.futures import ThreadPoolExecutor\n\n# --- IMPORTS ---\nimport gradio as gr\nfrom PIL import Image, ImageDraw, ImageFont\nfrom kaggle_secrets import UserSecretsClient\nimport whisperx\nfrom google import genai\nfrom google.genai import types\nimport mediapipe as mp\nfrom mediapipe.tasks import python\nfrom mediapipe.tasks.python import vision\n\n# --- CONFIG ---\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 16\nMAX_DURATION = 60\n\n# --- AUTH ---\ntry:\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    client = genai.Client(api_key=api_key)\nexcept Exception as e:\n    print(f\"âŒ Secret Error: {e}\")\n\n\n# --- CORE ENGINE ---\n\nclass ContentBrain:\n    def __init__(self):\n        print(f\"ğŸš€ Loading WhisperX on {DEVICE}...\")\n        self.model = whisperx.load_model(\"large-v3-turbo\", DEVICE, compute_type=\"float16\", vad_method=\"silero\")\n        self.align_model, self.metadata = whisperx.load_align_model(language_code=\"en\", device=DEVICE)\n\n    def transcribe(self, audio_path):\n        result = self.model.transcribe(audio_path, batch_size=BATCH_SIZE)\n        aligned = whisperx.align(result[\"segments\"], self.align_model, self.metadata, audio_path, DEVICE, return_char_alignments=False)\n        return aligned\n\n    def analyze(self, text):\n        print(\"ğŸ§  Thinking (Gemini 2.5 Flash)...\")\n        prompt = f\"\"\"\n        Act as a viral content strategist. Analyze this transcript.\n        Identify exactly 3 segments (30-50s duration) that work as standalone viral shorts.\n        Return JSON ONLY: [{{\"start_text\": \"unique start phrase\", \"end_text\": \"unique end phrase\", \"title\": \"Engaging Headline\"}}]\n        Transcript: {text[:150000]}...\n        \"\"\"\n        try:\n            res = client.models.generate_content(\n                model=\"gemini-2.5-flash\", \n                contents=prompt,\n                config=types.GenerateContentConfig(temperature=0.7, response_mime_type=\"application/json\")\n            )\n            return json.loads(res.text)\n        except: return []\n\nclass SmartCam:\n    def __init__(self):\n        base_opts = python.BaseOptions(model_asset_path='detector.tflite')\n        opts = vision.FaceDetectorOptions(base_options=base_opts, min_detection_confidence=0.5)\n        self.detector = vision.FaceDetector.create_from_options(opts)\n\n    def get_face_center(self, frame):\n        mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n        res = self.detector.detect(mp_img)\n        if res.detections:\n            largest = max(res.detections, key=lambda d: d.bounding_box.width)\n            return (largest.bounding_box.origin_x + (largest.bounding_box.width / 2)) / frame.shape[1]\n        return 0.5\n\nclass Renderer:\n    def __init__(self):\n        self.font_path = \"/usr/share/fonts/truetype/roboto/Roboto-Black.ttf\"\n        try:\n            self.font_size = 75\n            self.font = ImageFont.truetype(self.font_path, self.font_size)\n            self.small_font = ImageFont.truetype(self.font_path, 40)\n        except:\n            self.font = ImageFont.load_default(); self.small_font = ImageFont.load_default()\n\n    def get_text_width(self, words, draw):\n        total = 0\n        for wd in words:\n            bbox = draw.textbbox((0,0), wd['word'], font=self.font)\n            total += (bbox[2]-bbox[0]) + 20\n        return total - 20\n\n    def draw_wrapped_title(self, draw, title, w):\n        words = title.upper().split()\n        lines = []\n        curr = []\n        for word in words:\n            test = curr + [word]\n            bbox = draw.textbbox((0,0), \" \".join(test), font=self.small_font)\n            if (bbox[2]-bbox[0]) < (w - 100): curr = test\n            else: lines.append(\" \".join(curr)); curr = [word]\n        lines.append(\" \".join(curr))\n        \n        y = 80\n        for line in lines:\n            bbox = draw.textbbox((0,0), line, font=self.small_font)\n            x = (w - (bbox[2]-bbox[0])) // 2\n            draw.text((x, y), line, font=self.small_font, fill=\"#00ffff\", stroke_width=3, stroke_fill=\"black\")\n            y += 50\n\n    def draw_karaoke(self, frame, words, time, title):\n        draw = ImageDraw.Draw(frame)\n        w, h = frame.size\n        self.draw_wrapped_title(draw, title, w)\n        \n        active_idx = -1\n        for i, word in enumerate(words):\n            if word['start'] <= time <= word['end'] + 0.2:\n                active_idx = i; break\n        \n        if active_idx == -1: return frame\n        \n        chunk_size = 3\n        start = (active_idx // chunk_size) * chunk_size\n        end = min(len(words), start + chunk_size)\n        visible = words[start:end]\n        \n        if self.get_text_width(visible, draw) > (w - 80):\n            visible = [words[active_idx]]\n            \n        y = h - 450\n        x = (w - self.get_text_width(visible, draw)) // 2\n        \n        for wd in visible:\n            color = \"#FFE135\" if wd == words[active_idx] else \"white\"\n            draw.text((x, y), wd['word'], font=self.font, fill=color, stroke_width=5, stroke_fill=\"black\")\n            bbox = draw.textbbox((0,0), wd['word'], font=self.font)\n            x += (bbox[2]-bbox[0]) + 20\n            \n        return frame\n\n# --- WORKER FUNCTIONS ---\nbrain = ContentBrain()\ncam = SmartCam()\nrenderer = Renderer()\n\ndef clean_filename(title):\n    clean = re.sub(r'[^\\w\\s-]', '', title).strip().lower()\n    return re.sub(r'[-\\s]+', '_', clean)\n\ndef render_worker(args):\n    i, hook, vid_path, all_words = args\n    print(f\"   â–¶ï¸ Processing: {hook['title']}\")\n    \n    start_t, end_t = 0, 0\n    s_txt, e_txt = hook['start_text'].strip(), hook['end_text'].strip()\n    \n    for w in all_words: \n        if s_txt.startswith(w['word'].strip()): start_t = w['start']; break\n            \n    if start_t > 0:\n        for w in all_words:\n            if w['start'] > start_t and w['end'] < (start_t + MAX_DURATION) and e_txt.endswith(w['word'].strip()):\n                end_t = w['end']\n    \n    if end_t <= start_t: start_t = i*60+60; end_t = start_t + 50\n    if (end_t - start_t) > MAX_DURATION: end_t = start_t + MAX_DURATION\n    \n    cap = cv2.VideoCapture(vid_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    start_f, end_f = int(start_t*fps), int(end_t*fps)\n    \n    safe_title = clean_filename(hook['title'])\n    out = f\"{safe_title}.mp4\"\n    tmp = f\"temp_{i}.mp4\"\n    \n    writer = cv2.VideoWriter(tmp, cv2.VideoWriter_fourcc(*'mp4v'), fps, (720, 1280))\n    cap.set(cv2.CAP_PROP_POS_FRAMES, start_f)\n    \n    curr_f = start_f\n    curr_center = 0.5\n    \n    while curr_f < end_f:\n        ret, frame = cap.read()\n        if not ret: break\n        \n        tgt_center = cam.get_face_center(frame)\n        curr_center = curr_center * 0.9 + tgt_center * 0.1\n        \n        h, w, _ = frame.shape\n        tgt_w = int(h * (9/16))\n        if tgt_w % 2 != 0: tgt_w -= 1\n        \n        cx = int(curr_center * w)\n        x1 = max(0, min(cx - (tgt_w // 2), w - tgt_w))\n        \n        final = cv2.resize(frame[0:h, x1:x1+tgt_w], (720, 1280))\n        img = Image.fromarray(cv2.cvtColor(final, cv2.COLOR_BGR2RGB))\n        img = renderer.draw_karaoke(img, all_words, curr_f/fps, hook['title'])\n        writer.write(cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n        curr_f += 1\n        \n    cap.release(); writer.release()\n    \n    subprocess.run([\n        \"ffmpeg\", \"-y\", \"-i\", tmp, \"-ss\", str(start_t), \"-to\", str(end_t), \"-i\", vid_path,\n        \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \"-preset\", \"ultrafast\",\n        \"-c:a\", \"aac\", \"-map\", \"0:v:0\", \"-map\", \"1:a:0\", \"-shortest\", out\n    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n    \n    return out\n\ndef run_pipeline(vid_file, url, progress=gr.Progress()):\n    try:\n        # 1. Input\n        path = \"input.mp4\"\n        if vid_file: path = vid_file\n        elif url:\n            progress(0.1, desc=\"Loading Video...\")\n            cmd = [\n                \"yt-dlp\", \n                \"--add-header\", \"User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\",\n                \"-f\", \"bestvideo[ext=mp4][vcodec^=avc]+bestaudio[ext=m4a]/best[ext=mp4]/best\", \n                \"--force-overwrites\", \n                \"-o\", path, \n                url\n            ]\n            result = subprocess.run(cmd, capture_output=True, text=True)\n            if result.returncode != 0:\n                return [gr.update(value=None), gr.update(value=None), gr.update(value=None), f\"âŒ Download Failed:\\n{result.stderr[-200:]}\"]\n        else: return [gr.update(value=None), gr.update(value=None), gr.update(value=None), \"âŒ No input provided\"]\n\n        if not os.path.exists(path): return [gr.update(value=None), gr.update(value=None), gr.update(value=None), \"âŒ Download failed (File not found)\"]\n\n        # 2. Audio\n        progress(0.2, desc=\"Analysing Audio...\")\n        subprocess.run([\"ffmpeg\", \"-y\", \"-i\", path, \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", \"temp.wav\"], stdout=subprocess.DEVNULL)\n        \n        try: aligned = brain.transcribe(\"temp.wav\")\n        except Exception as e: return [gr.update(value=None), gr.update(value=None), gr.update(value=None), f\"âŒ Whisper Error: {e}\"]\n        \n        text = \" \".join([s['text'] for s in aligned['segments']])\n        words = []\n        for s in aligned['segments']: words.extend(s['words'])\n\n        # 3. AI\n        progress(0.4, desc=\"Selecting Hooks...\")\n        hooks = brain.analyze(text)\n        if not hooks: return [gr.update(value=None), gr.update(value=None), gr.update(value=None), \"âŒ No viral hooks found by AI\"]\n\n        # 4. Render\n        progress(0.6, desc=\"Rendering...\")\n        with ThreadPoolExecutor(max_workers=3) as exe:\n            files = list(exe.map(render_worker, [(i, h, path, words) for i, h in enumerate(hooks)]))\n        \n        # 5. Dynamic Return (Update Labels)\n        outputs = []\n        for i, f in enumerate(files):\n            # Dynamic Label Update: \"Reel 1\" -> \"Actual Title\"\n            outputs.append(gr.update(value=f, label=hooks[i]['title']))\n        \n        while len(outputs) < 3: \n            outputs.append(gr.update(value=None, label=\"No Reel Generated\"))\n            \n        outputs.append(\"âœ… Processing Complete!\")\n        return outputs[0], outputs[1], outputs[2], outputs[3]\n    \n    except Exception as e:\n        return [gr.update(value=None), gr.update(value=None), gr.update(value=None), f\"âŒ Critical Error:\\n{str(e)}\"]\n\n\n# --- GRADIO UI ---\n\nwith gr.Blocks(title=\"ViralReel AI\") as app:\n    gr.Markdown(\"# ğŸš€ ViralReel AI\")\n    gr.Markdown(\"Automated Short-Form Content Generator Â· Powered by Gemini & WhisperX\")\n    \n    with gr.Column():\n        with gr.Tabs():\n            with gr.TabItem(\"Upload Video\"):\n                v_in = gr.Video(label=\"Source File\")\n            with gr.TabItem(\"Paste URL\"):\n                l_in = gr.Textbox(label=\"YouTube / Drive Link\", placeholder=\"https://...\")\n        \n        btn = gr.Button(\"Generate Reels\", variant=\"primary\")\n        status = gr.Textbox(label=\"System Logs\", interactive=False)\n    \n    with gr.Row():\n        o1 = gr.Video(label=\"Pending Reel 1...\")\n        o2 = gr.Video(label=\"Pending Reel 2...\")\n        o3 = gr.Video(label=\"Pending Reel 3...\")\n\n    btn.click(\n        run_pipeline, \n        inputs=[v_in, l_in], \n        outputs=[o1, o2, o3, status]\n    )\n\napp.queue().launch(share=True, debug=True)","metadata":{"execution":{"iopub.status.busy":"2026-01-17T20:03:02.799970Z","iopub.execute_input":"2026-01-17T20:03:02.800285Z","iopub.status.idle":"2026-01-17T20:11:55.387836Z","shell.execute_reply.started":"2026-01-17T20:03:02.800246Z","shell.execute_reply":"2026-01-17T20:11:55.387272Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2026-01-17 20:03:13.443397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768680193.638175      94 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768680193.694925      94 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768680194.177729      94 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768680194.177769      94 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768680194.177772      94 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768680194.177775      94 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"ğŸš€ Loading WhisperX on cuda...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n  torchaudio.list_audio_backends()\n/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n  available_backends = torchaudio.list_audio_backends()\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\nDEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocabulary.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a47b75d68e446a5bf050fed25d344f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd9b056a47f840e69100c7f2c87dc652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aadbd09dc3b414ea8722f0348933127"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16a03aaf49b5494c817416480a1cf84a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.bin:   0%|          | 0.00/1.62G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ec7d317742d4e5c8e3f7e6906ac37b3"}},"metadata":{}},{"name":"stdout","text":"2026-01-17 20:03:46 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n2026-01-17 20:03:46 - whisperx.vads.silero - INFO - Performing voice activity detection using Silero...\nDownloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360M/360M [00:01<00:00, 344MB/s] \nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1768680230.652316      94 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nW0000 00:00:1768680230.657985    1070 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://c60af9afdf407682b9.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://c60af9afdf407682b9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stderr","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input.mp4':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2avc1mp41\n    encoder         : Lavf58.76.100\n  Duration: 00:04:21.78, start: 0.000000, bitrate: 2583 kb/s\n  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1080 [SAR 1:1 DAR 16:9], 2450 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      vendor_id       : [0][0][0][0]\n  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      vendor_id       : [0][0][0][0]\nStream mapping:\n  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'temp.wav':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2avc1mp41\n    ISFT            : Lavf58.76.100\n  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n    Metadata:\n      handler_name    : ISO Media file produced by Google Inc.\n      vendor_id       : [0][0][0][0]\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=    8181kB time=00:04:21.78 bitrate= 256.0kbits/s speed= 515x    \nvideo:0kB audio:8181kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000931%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-17 20:04:38 - whisperx.asr - INFO - Detected language: en (1.00) in first 30s of audio\nğŸ§  Thinking (Gemini 2.5 Flash)...\n   â–¶ï¸ Processing: Dance Stage USA: Cheap Thrills Kick-off!\n   â–¶ï¸ Processing: Get Ready to Rock with Sia!\n   â–¶ï¸ Processing: Unleash Yourself! Sia's Cheap Thrills Lyrics\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n","output_type":"stream"},{"name":"stdout","text":"Keyboard interruption in main thread... closing server.\nKilling tunnel 127.0.0.1:7860 <> https://c60af9afdf407682b9.gradio.live\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}